{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/trokas/ai_primer.git","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:25.047739Z","iopub.execute_input":"2023-10-03T17:57:25.047963Z","iopub.status.idle":"2023-10-03T17:57:33.948191Z","shell.execute_reply.started":"2023-10-03T17:57:25.047940Z","shell.execute_reply":"2023-10-03T17:57:33.947071Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'ai_primer'...\nremote: Enumerating objects: 2876, done.\u001b[K\nremote: Counting objects: 100% (918/918), done.\u001b[K\nremote: Compressing objects: 100% (387/387), done.\u001b[K\nremote: Total 2876 (delta 485), reused 862 (delta 431), pack-reused 1958\u001b[K\nReceiving objects: 100% (2876/2876), 109.02 MiB | 23.08 MiB/s, done.\nResolving deltas: 100% (1421/1421), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:33.950262Z","iopub.execute_input":"2023-10-03T17:57:33.951239Z","iopub.status.idle":"2023-10-03T17:57:43.829918Z","shell.execute_reply.started":"2023-10-03T17:57:33.951204Z","shell.execute_reply":"2023-10-03T17:57:43.828954Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"x=np.load(\"ai_primer/flatland_train.npz\")","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:43.831364Z","iopub.execute_input":"2023-10-03T17:57:43.832216Z","iopub.status.idle":"2023-10-03T17:57:43.838205Z","shell.execute_reply.started":"2023-10-03T17:57:43.832171Z","shell.execute_reply":"2023-10-03T17:57:43.837285Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential(\n    [\n        keras.Input(shape=(50, 50, 1)),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.Dropout(0.4),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n\n        layers.Flatten(),\n        layers.Dense(80, activation=\"relu\"),\n        layers.Dense(5, activation=\"softmax\")\n    ]\n)\n\nopt=keras.optimizers.AdamW(learning_rate=0.001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:43.840848Z","iopub.execute_input":"2023-10-03T17:57:43.841445Z","iopub.status.idle":"2023-10-03T17:57:49.758757Z","shell.execute_reply.started":"2023-10-03T17:57:43.841395Z","shell.execute_reply":"2023-10-03T17:57:49.757684Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data=tf.convert_to_tensor(torch.tensor(x[\"X\"], dtype=torch.float32)/255)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:49.760313Z","iopub.execute_input":"2023-10-03T17:57:49.760639Z","iopub.status.idle":"2023-10-03T17:57:50.455983Z","shell.execute_reply.started":"2023-10-03T17:57:49.760608Z","shell.execute_reply":"2023-10-03T17:57:50.455062Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Sutvarkome labels reiksmes ir paverciame labels i kategorini vektoriu\n\nlabels=x['y']\nlabels[labels!=0]-=2\nlabels=tf.convert_to_tensor(torch.tensor(labels, dtype=torch.int8))\nlabels=keras.utils.to_categorical(labels, 5)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:50.457355Z","iopub.execute_input":"2023-10-03T17:57:50.457682Z","iopub.status.idle":"2023-10-03T17:57:50.477909Z","shell.execute_reply.started":"2023-10-03T17:57:50.457651Z","shell.execute_reply":"2023-10-03T17:57:50.477146Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Is 2000 paskutiniu paveiksleliu pagaminame 2000 augmented paveiksleliu. Augmented paveikslelis gaunamas dvigubai sumazinant paprasta \n#paveiksleli ir atsitiktineje vietoje uzdedant ji ant juodo fono.\n\nimport time\n\nimage_array=x[\"X\"]\nmodified_data=[]\nfor i in range(8000, 10000):\n    unmodified_image=image_array[i]\n    offset=[int(j) for j in torch.randint(0, 25, (2,))]\n    background=np.zeros((50, 50))\n    for j in range(25):\n        for k in range(25):\n            background[j+offset[0]][k+offset[1]]=np.mean(unmodified_image[2*j:2*j+2, 2*k:2*k+2])\n    modified_data.append(background)\n    if i%100==0:\n        print(i)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:57:50.479072Z","iopub.execute_input":"2023-10-03T17:57:50.479901Z","iopub.status.idle":"2023-10-03T17:58:00.399117Z","shell.execute_reply.started":"2023-10-03T17:57:50.479870Z","shell.execute_reply":"2023-10-03T17:58:00.397720Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"8000\n8100\n8200\n8300\n8400\n8500\n8600\n8700\n8800\n8900\n9000\n9100\n9200\n9300\n9400\n9500\n9600\n9700\n9800\n9900\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_tensor=tf.convert_to_tensor(np.stack(modified_data))/255\nmodified_tensor=tf.cast(modified_tensor, tf.float32)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:58:00.400579Z","iopub.execute_input":"2023-10-03T17:58:00.400906Z","iopub.status.idle":"2023-10-03T17:58:00.479643Z","shell.execute_reply.started":"2023-10-03T17:58:00.400873Z","shell.execute_reply":"2023-10-03T17:58:00.478723Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Pakeiciame paskutinius 2000 paveiksleliu ju augmented paveiksleliais. Kadangi augmented paveikslelyje objektas lieka tas pats, \n#labels vektoriaus keisti nereikia\n\nfinal_data=tf.concat([data[:8000], modified_tensor], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:58:00.480819Z","iopub.execute_input":"2023-10-03T17:58:00.481495Z","iopub.status.idle":"2023-10-03T17:58:00.498879Z","shell.execute_reply.started":"2023-10-03T17:58:00.481462Z","shell.execute_reply":"2023-10-03T17:58:00.498049Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for j in range(25):\n    model.fit(final_data[:9500], labels[:9500], batch_size=100, epochs=10)\n    print(\"*\"*100)\n    print(f\"Epoch {(j+1)*10}\")\n    #tikriname generalization su nemodifikuotais paveiksleliais\n    model.evaluate(data[9500:], labels[9500:])\n    #tikriname generalization su modifikuotais paveiksleliais\n    model.evaluate(modified_tensor[1500:], labels[9500:])\n    print(\"*\"*100)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:58:00.502203Z","iopub.execute_input":"2023-10-03T17:58:00.502480Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2023-10-03 17:58:01.688803: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"}]},{"cell_type":"code","source":"#Sumaziname learning rate geresniam konvergavimui\n\nopt=keras.optimizers.AdamW(learning_rate=0.0001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(25):\n    model.fit(final_data[:9500], labels[:9500], batch_size=100, epochs=10)\n    print(\"*\"*100)\n    print(f\"Epoch {(j+1)*10}\")\n    #tikriname generalization su nemodifikuotais paveiksleliais\n    model.evaluate(data[9500:], labels[9500:])\n    #tikriname generalization su modifikuotais paveiksleliais\n    model.evaluate(modified_tensor[1500:], labels[9500:])\n    print(\"*\"*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}