{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/trokas/ai_primer.git","metadata":{"execution":{"iopub.status.busy":"2023-10-03T17:50:59.241640Z","iopub.execute_input":"2023-10-03T17:50:59.241869Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Cloning into 'ai_primer'...\nremote: Enumerating objects: 2876, done.\u001b[K\nremote: Counting objects: 100% (918/918), done.\u001b[K\nremote: Compressing objects: 100% (387/387), done.\u001b[K\nremote: Total 2876 (delta 485), reused 862 (delta 431), pack-reused 1958\u001b[K\nReceiving objects: 100% (2876/2876), 109.02 MiB | 23.99 MiB/s, done.\nResolving deltas:  22% (313/1421)\r","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=np.load(\"ai_primer/flatland_train.npz\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential(\n    [\n        keras.Input(shape=(50, 50, 1)),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Dropout(0.4),\n        layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n        layers.Dropout(0.4),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n\n        layers.Flatten(),\n        layers.Dense(80, activation=\"relu\"),\n        layers.Dense(5, activation=\"softmax\")\n    ]\n)\n\nopt=keras.optimizers.AdamW(learning_rate=0.001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=tf.convert_to_tensor(torch.tensor(x[\"X\"], dtype=torch.float32)/255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sutvarkome labels reiksmes ir paverciame labels i kategorini vektoriu\n\nlabels=x['y']\nlabels[labels!=0]-=2\nlabels=tf.convert_to_tensor(torch.tensor(labels, dtype=torch.int8))\nlabels=keras.utils.to_categorical(labels, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Is 2000 paskutiniu paveiksleliu pagaminame 2000 augmented paveiksleliu. Augmented paveikslelis gaunamas dvigubai sumazinant paprasta \n#paveiksleli ir atsitiktineje vietoje uzdedant ji ant juodo fono.\n\nimport time\n\nimage_array=x[\"X\"]\nmodified_data=[]\nfor i in range(8000, 10000):\n    unmodified_image=image_array[i]\n    offset=[int(j) for j in torch.randint(0, 25, (2,))]\n    background=np.zeros((50, 50))\n    for j in range(25):\n        for k in range(25):\n            background[j+offset[0]][k+offset[1]]=np.mean(unmodified_image[2*j:2*j+2, 2*k:2*k+2])\n    modified_data.append(background)\n    if i%100==0:\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_tensor=tf.convert_to_tensor(np.stack(modified_data))/255\nmodified_tensor=tf.cast(modified_tensor, tf.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pakeiciame paskutinius 2000 paveiksleliu ju augmented paveiksleliais. Kadangi augmented paveikslelyje objektas lieka tas pats, \n#labels vektoriaus keisti nereikia\n\nfinal_data=tf.concat([data[:8000], modified_tensor], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(10):\n    model.fit(final_data[:9500], labels[:9500], batch_size=100, epochs=10)\n    print(\"*\"*100)\n    print(f\"Epoch {(j+1)*10}\")\n    #tikriname generalization su nemodifikuotais paveiksleliais\n    model.evaluate(data[9500:], labels[9500:])\n    #tikriname generalization su modifikuotais paveiksleliais\n    model.evaluate(modified_tensor[1500:], labels[9500:])\n    print(\"*\"*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sumaziname learning rate geresniam konvergavimui\n\nopt=keras.optimizers.AdamW(learning_rate=0.0001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(25):\n    model.fit(final_data[:9500], labels[:9500], batch_size=100, epochs=10)\n    print(\"*\"*100)\n    print(f\"Epoch {(j+1)*10}\")\n    #tikriname generalization su nemodifikuotais paveiksleliais\n    model.evaluate(data[9500:], labels[9500:])\n    #tikriname generalization su modifikuotais paveiksleliais\n    model.evaluate(modified_tensor[1500:], labels[9500:])\n    print(\"*\"*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}